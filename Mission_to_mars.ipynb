{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize browser\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit the NASA page\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape page into soup\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NASA to Host Media Call on Next Mars Landing Site\n",
      "Paragraph: NASA will host a media teleconference at 9 a.m. PST (noon EST) Monday, Nov. 19, to provide details about the Mars 2020 roverâ€™s landing site on the Red Planet.\n"
     ]
    }
   ],
   "source": [
    "#Find the latest News Title and Paragraph Text.\n",
    "news_title = soup.find(\"div\",class_=\"content_title\").text\n",
    "news_p= soup.find(\"div\", class_=\"article_teaser_body\").text\n",
    "print(f\"Title: {news_title}\")\n",
    "print(f\"Paragraph: {news_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use splinter to navigate the site and find the image url for the current Featured Mars Image \n",
    "url_image = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url_image)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "image = soup.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "img_url = \"https://jpl.nasa.gov\"+image\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a complete url string to a variable called `featured_image_url`\n",
    "featured_image_url = img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit the Mars Weather twitter account and scrape the latest Mars weather tweet from the page. \n",
    "weather_url = 'https://twitter.com/marswxreport?lang=en '\n",
    "browser.visit(weather_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the tweet text for the weather report as a variable called mars_weather.\n",
    "html_weather = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = bs(html_weather, 'html.parser')\n",
    "\n",
    "# Find tweets\n",
    "latest_M_tweets = soup.find_all('div', class_='js-tweet-text-container')\n",
    "\n",
    "# Retrieve tweets and  heck for words that are weather related (Sol and pressure)and exclude non weather words\n",
    "for tweet in latest_M_tweets: \n",
    "    weather_tweet = tweet.find('p').text\n",
    "    if 'Sol' and 'pressure' in weather_tweet:\n",
    "        print(weather_tweet)\n",
    "        break\n",
    "    else: \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = weather_tweet\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit the Mars Facts site and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "facts_url = 'http://space-facts.com/mars/'\n",
    "#Use Pandas to convert the data to a HTML table string\n",
    "mars_facts = pd.read_html(facts_url)\n",
    "# Find the mars facts and assign it to `mars_fact_df`\n",
    "mars_fact_df = mars_facts[0]\n",
    "mars_fact_df.columns = ['Description','Value']\n",
    "# Set the index \n",
    "mars_fact_df.set_index('Description', inplace=True)\n",
    "# Save html \n",
    "mars_fact_df.to_html()\n",
    "data = mars_fact_df.to_dict(orient='records')  \n",
    "# Display mars_df\n",
    "mars_fact_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Hemispheres URL\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "\n",
    "# Empty list of image urls\n",
    "hemisphere_image_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valles Marineris:\n",
    "# Setting up splinter\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "browser.visit(url)\n",
    "\n",
    "\n",
    "# Moving through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Valles Marineris Hemisphere')\n",
    "time.sleep(5)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "valles_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dictionary\n",
    "valles_marineris = {\n",
    "    \"title\": \"Valles Marineris Hemisphere\",\n",
    "    \"img_url\": valles_link\n",
    "}\n",
    "\n",
    "# Appending dictionary\n",
    "hemisphere_image_urls.append(valles_marineris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cerberus:\n",
    "# Setting up splinter\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "browser.visit(url)\n",
    "\n",
    "# Moving through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Cerberus Hemisphere')\n",
    "time.sleep(5)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "cerberus_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dictionary\n",
    "cerberus = {\n",
    "    \"title\": \"Cerberus Hemisphere\",\n",
    "    \"img_url\": cerberus_link\n",
    "}\n",
    "\n",
    "# Appending dictionary\n",
    "hemisphere_image_urls.append(cerberus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schiaparelli\n",
    "# Setting up splinter\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "browser.visit(url)\n",
    "\n",
    "# Moving through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Schiaparelli Hemisphere')\n",
    "time.sleep(5)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "schiaparelli_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dictionary\n",
    "schiaparelli = {\n",
    "    \"title\": \"Schiaparelli Hemisphere\",\n",
    "    \"img_url\": schiaparelli_link\n",
    "}\n",
    "\n",
    "# Appending dictionary\n",
    "hemisphere_image_urls.append(schiaparelli)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Valles Marineris Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}, {'title': 'Cerberus Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "#Syrtis Major\n",
    "# Setting up splinter\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "browser.visit(url)\n",
    "\n",
    "# Moving through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Syrtis Major Hemisphere')\n",
    "time.sleep(5)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "syrtis_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dictionary\n",
    "syrtis_major = {\n",
    "    \"title\": \"Syrtis Major Hemisphere\",\n",
    "    \"img_url\": syrtis_link\n",
    "}\n",
    "\n",
    "# Appending dictionary\n",
    "hemisphere_image_urls.append(syrtis_major)\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
